{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75a6c5ab",
   "metadata": {},
   "source": [
    "## Running OWL2Vec*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2658935d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/natalie/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "INFO: Access the ontology ...\n",
      "INFO: There are 1945 triples in the ontology\n",
      "INFO: Calculate the ontology projection ...\n",
      "INFO: Creating ontology graph projection...\n",
      "INFO: \tExtracting subsumption triples\n",
      "INFO: \t\tTime extracting subsumption: 0.7556407451629639 seconds \n",
      "INFO: \tExtracting equivalence triples\n",
      "INFO: \t\tTime extracting equivalences: 0.014490127563476562 seconds \n",
      "INFO: \tExtracting class membership triples.\n",
      "INFO: \t\tTime extracting class membership: 0.17450284957885742 seconds \n",
      "INFO: \tExtracting sameAs triples\n",
      "INFO: \t\tTime extracting sameAs: 0.004415988922119141 seconds \n",
      "INFO: \tExtracting triples associated to hasBase\n",
      "INFO: \t\tTime extracting triples for property: 0.07584285736083984 seconds \n",
      "INFO: \tExtracting triples associated to hasIngredient\n",
      "INFO: \t\tTime extracting triples for property: 0.07369112968444824 seconds \n",
      "INFO: \tExtracting triples associated to isBaseOf\n",
      "INFO: \t\tTime extracting triples for property: 0.07513189315795898 seconds \n",
      "INFO: \tExtracting triples associated to hasCountryOfOrigin\n",
      "INFO: \t\tTime extracting triples for property: 0.07577085494995117 seconds \n",
      "INFO: \tExtracting triples associated to isIngredientOf\n",
      "INFO: \t\tTime extracting triples for property: 0.07600998878479004 seconds \n",
      "INFO: \tExtracting triples associated to hasSpiciness\n",
      "INFO: \t\tTime extracting triples for property: 0.08916091918945312 seconds \n",
      "INFO: \tExtracting triples associated to hasTopping\n",
      "INFO: \t\tTime extracting triples for property: 0.12495088577270508 seconds \n",
      "INFO: \tExtracting triples associated to isToppingOf\n",
      "INFO: \t\tTime extracting triples for property: 0.06946420669555664 seconds \n",
      "INFO: \tExtracting data property assertions\n",
      "INFO: \t\tTime extracting data property assertions: 0.00033593177795410156 seconds \n",
      "INFO: \tExtracting complex equivalence axioms\n",
      "INFO: \t\tTime extracting complex equivalence axioms: 2.260654926300049 seconds \n",
      "INFO: \tExtracting annotations.\n",
      "INFO: \t\tTime extracting annotations: 0.41511082649230957 seconds \n",
      "INFO: Projection created into a Graph object (RDFlib library)\n",
      "INFO: Projection saved into turtle file: ./cache/projection.ttl\n",
      "INFO: Extract classes and individuals ...\n",
      "INFO: Extract axioms ...\n",
      "INFO: Extract annotations ...\n",
      "INFO: Generate URI document ...\n",
      "INFO: Extracted 3350 walks for 104 seed entities\n",
      "INFO: Extracted 279 axiom sentences\n",
      "INFO: Generate literal document ...\n",
      "INFO: Extracted 34 annotation sentences\n",
      "INFO: Generate mixture document ...\n",
      "INFO: URI_Doc: 3629, Lit_Doc: 12069, Mix_Doc: 3629\n",
      "INFO: Time for document construction: 5.504384994506836 seconds\n",
      "INFO: Train the language model ...\n",
      "INFO: collecting all words and their counts\n",
      "INFO: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO: PROGRESS: at sentence #10000, processed 58729 words, keeping 693 word types\n",
      "INFO: collected 784 word types from a corpus of 113363 raw words and 19327 sentences\n",
      "INFO: Creating a fresh vocabulary\n",
      "INFO: Word2Vec lifecycle event {'msg': 'effective_min_count=1 retains 784 unique words (100.0%% of original 784, drops 0)', 'datetime': '2023-03-27T17:01:42.543943', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  5 2022, 01:53:17) \\n[Clang 12.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "INFO: Word2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 113363 word corpus (100.0%% of original 113363, drops 0)', 'datetime': '2023-03-27T17:01:42.544373', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  5 2022, 01:53:17) \\n[Clang 12.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "INFO: deleting the raw counts dictionary of 784 items\n",
      "INFO: sample=0.001 downsamples 57 most-common words\n",
      "INFO: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 53150.732868721985 word corpus (46.9%% of prior 113363)', 'datetime': '2023-03-27T17:01:42.548935', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  5 2022, 01:53:17) \\n[Clang 12.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "INFO: estimated required memory for 784 words and 100 dimensions: 1019200 bytes\n",
      "INFO: resetting layer weights\n",
      "INFO: Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-03-27T17:01:42.558722', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  5 2022, 01:53:17) \\n[Clang 12.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "INFO: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 784 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=25 window=5 shrink_windows=True', 'datetime': '2023-03-27T17:01:42.559140', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  5 2022, 01:53:17) \\n[Clang 12.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "INFO: worker thread finished; awaiting finish of 9 more threads\n",
      "INFO: worker thread finished; awaiting finish of 8 more threads\n",
      "INFO: worker thread finished; awaiting finish of 7 more threads\n",
      "INFO: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 1 : training on 113363 raw words (53272 effective words) took 0.1s, 463664 effective words/s\n",
      "INFO: worker thread finished; awaiting finish of 9 more threads\n",
      "INFO: worker thread finished; awaiting finish of 8 more threads\n",
      "INFO: worker thread finished; awaiting finish of 7 more threads\n",
      "INFO: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 2 : training on 113363 raw words (52994 effective words) took 0.1s, 473661 effective words/s\n",
      "INFO: worker thread finished; awaiting finish of 9 more threads\n",
      "INFO: worker thread finished; awaiting finish of 8 more threads\n",
      "INFO: worker thread finished; awaiting finish of 7 more threads\n",
      "INFO: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 3 : training on 113363 raw words (53110 effective words) took 0.1s, 522327 effective words/s\n",
      "INFO: worker thread finished; awaiting finish of 9 more threads\n",
      "INFO: worker thread finished; awaiting finish of 8 more threads\n",
      "INFO: worker thread finished; awaiting finish of 7 more threads\n",
      "INFO: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 4 : training on 113363 raw words (53321 effective words) took 0.1s, 482097 effective words/s\n",
      "INFO: worker thread finished; awaiting finish of 9 more threads\n",
      "INFO: worker thread finished; awaiting finish of 8 more threads\n",
      "INFO: worker thread finished; awaiting finish of 7 more threads\n",
      "INFO: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO: worker thread finished; awaiting finish of 4 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 5 : training on 113363 raw words (53301 effective words) took 0.1s, 481553 effective words/s\n",
      "INFO: worker thread finished; awaiting finish of 9 more threads\n",
      "INFO: worker thread finished; awaiting finish of 8 more threads\n",
      "INFO: worker thread finished; awaiting finish of 7 more threads\n",
      "INFO: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 6 : training on 113363 raw words (53230 effective words) took 0.1s, 528715 effective words/s\n",
      "INFO: worker thread finished; awaiting finish of 9 more threads\n",
      "INFO: worker thread finished; awaiting finish of 8 more threads\n",
      "INFO: worker thread finished; awaiting finish of 7 more threads\n",
      "INFO: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 7 : training on 113363 raw words (53040 effective words) took 0.1s, 513453 effective words/s\n",
      "INFO: worker thread finished; awaiting finish of 9 more threads\n",
      "INFO: worker thread finished; awaiting finish of 8 more threads\n",
      "INFO: worker thread finished; awaiting finish of 7 more threads\n",
      "INFO: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 8 : training on 113363 raw words (52948 effective words) took 0.1s, 523975 effective words/s\n",
      "INFO: worker thread finished; awaiting finish of 9 more threads\n",
      "INFO: worker thread finished; awaiting finish of 8 more threads\n",
      "INFO: worker thread finished; awaiting finish of 7 more threads\n",
      "INFO: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 9 : training on 113363 raw words (53064 effective words) took 0.1s, 511884 effective words/s\n",
      "INFO: worker thread finished; awaiting finish of 9 more threads\n",
      "INFO: worker thread finished; awaiting finish of 8 more threads\n",
      "INFO: worker thread finished; awaiting finish of 7 more threads\n",
      "INFO: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 10 : training on 113363 raw words (53230 effective words) took 0.1s, 499466 effective words/s\n",
      "INFO: Word2Vec lifecycle event {'msg': 'training on 1133630 raw words (531510 effective words) took 1.2s, 454090 effective words/s', 'datetime': '2023-03-27T17:01:43.730007', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  5 2022, 01:53:17) \\n[Clang 12.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "INFO: Word2Vec lifecycle event {'params': 'Word2Vec(vocab=784, vector_size=100, alpha=0.025)', 'datetime': '2023-03-27T17:01:43.730270', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  5 2022, 01:53:17) \\n[Clang 12.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "INFO: Time for learning the language model: 1.207711935043335 seconds\n",
      "INFO: Word2Vec lifecycle event {'fname_or_handle': './cache/output/ontology.embeddings', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-03-27T17:01:43.731031', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  5 2022, 01:53:17) \\n[Clang 12.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}\n",
      "INFO: not storing attribute cum_table\n",
      "INFO: saved ./cache/output/ontology.embeddings\n",
      "INFO: storing 784x100 projection weights into ./cache/output/ontology.embeddings.txt\n"
     ]
    }
   ],
   "source": [
    "from owl2vec_star import owl2vec_star\n",
    "\n",
    "\n",
    "#Parameters:\n",
    "# ontology_file\n",
    "# config_file\n",
    "# uri_doc\n",
    "# lit_doc\n",
    "# mix_doc\n",
    "gensim_model = owl2vec_star.extract_owl2vec_model(\"./case_studies/pizza/pizza.owl\", \"./default.cfg\", True, True, True)\n",
    "\n",
    "output_folder=\"./cache/output/\"\n",
    "\n",
    "#Gensim format\n",
    "gensim_model.save(output_folder+\"ontology.embeddings\")\n",
    "    #Txt format\n",
    "gensim_model.wv.save_word2vec_format(output_folder+\"ontology.embeddings.txt\", binary=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a78df2",
   "metadata": {},
   "source": [
    "## Loading embeddings and getting similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fdbcf09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: loading KeyedVectors object from ./cache/output/ontology.embeddings\n",
      "INFO: loading wv recursively from ./cache/output/ontology.embeddings.wv.* with mmap=r\n",
      "INFO: setting ignored attribute cum_table to None\n",
      "INFO: Word2Vec lifecycle event {'fname': './cache/output/ontology.embeddings', 'datetime': '2023-03-27T17:02:13.980977', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  5 2022, 01:53:17) \\n[Clang 12.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'loaded'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector for 'pizza'\n",
      "[-0.04923143  0.03200299  0.15921201  0.52758974  0.4132171   0.36031312\n",
      " -0.19683272 -0.01002887 -0.38390884 -0.511282   -0.06316078  0.02172357\n",
      " -0.12844695 -0.09718801  0.08315319  0.11974429 -0.03979231 -0.25627613\n",
      "  0.08273151  0.12136991  0.29910818  0.09670107  0.17595889  0.27772862\n",
      "  1.0166514  -0.05478515  0.3846501   0.11018349 -0.45911628  0.17375298\n",
      " -0.4196885  -0.01959671 -0.20985727  0.1593302   0.20798297 -0.08395791\n",
      "  0.5778252  -0.1114653  -0.37509868  0.0504577   0.27898005 -0.04469682\n",
      " -0.35666564 -0.1449909   0.51374304  0.2777079   0.22966939  0.21255931\n",
      "  0.2172322  -0.19617096 -0.1161456   0.10778292  0.03965979 -0.20363072\n",
      "  0.22257061  0.31229645 -0.2978499  -0.07765103 -0.00414777  0.23576258\n",
      "  0.5249893  -0.08907948 -0.3093439   0.58662075 -0.293579    0.0493212\n",
      " -0.31753156 -0.5276724  -0.0114496  -0.28855383 -0.0800975  -0.29440016\n",
      " -0.65844643 -0.28962508 -0.06934387  0.09806026  0.1473401  -0.39596212\n",
      " -0.10040962 -0.8117809   0.0638793   0.4833531  -0.5184869   0.15708818\n",
      "  0.23659581  0.07597492 -0.46655375 -0.43070894  0.26647133 -0.35914817\n",
      "  0.5777015   0.37376994  0.16161011  0.28472263 -0.0857394   0.5553659\n",
      " -0.29203448 -0.20424752  0.1695942   0.12113353]\n",
      "0.4064669\n",
      "0.77699864\n",
      "[('margherita pizza', 0.806885302066803), ('unclosedpizza', 0.7947215437889099), ('parmese pizza', 0.7811676263809204), ('caprina pizza', 0.7743346095085144), ('la reine pizza', 0.7586013078689575), ('mushroom pizza', 0.7551526427268982), ('rosa pizza', 0.7527878880500793), ('fiorentina pizza', 0.7512542605400085), ('soho pizza', 0.7499744296073914), ('pollo ad astra pizza', 0.745853841304779)]\n",
      "[('unclosedpizza', 0.8995453119277954), ('http://www.co-ode.org/ontologies/pizza/pizza.owl#Margherita', 0.8884984254837036), ('margherita pizza', 0.8859454393386841), ('unclosed', 0.8845601081848145), ('caprina pizza', 0.866087019443512), ('http://www.co-ode.org/ontologies/pizza/pizza.owl#Mushroom', 0.8648210763931274), ('parmese pizza', 0.8617496490478516), ('Margherita Pizza', 0.8596504926681519), ('mushroom pizza', 0.8588427305221558), ('interesting', 0.8511182069778442)]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "#Embedding vectors generated above\n",
    "model = KeyedVectors.load(\"./cache/output/ontology.embeddings\", mmap='r')\n",
    "wv = model.wv\n",
    "\n",
    "vector = wv['pizza']  # Get numpy vector of a word\n",
    "print(\"Vector for 'pizza'\")\n",
    "print(vector)\n",
    "\n",
    "#cosine similarity\n",
    "similarity = wv.similarity('pizza', 'http://www.co-ode.org/ontologies/pizza/pizza.owl#Pizza')\n",
    "print(similarity)\n",
    "\n",
    "similarity = wv.similarity('http://www.co-ode.org/ontologies/pizza/pizza.owl#Margherita', 'margherita')\n",
    "print(similarity)\n",
    "\n",
    "\n",
    "#Most similar cosine similarity\n",
    "result = wv.most_similar(positive=['margherita', 'pizza'])\n",
    "print(result)\n",
    "\n",
    "#Most similar entities: cosmul\n",
    "result = wv.most_similar_cosmul(positive=['margherita'])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c417dfe4",
   "metadata": {},
   "source": [
    "Task 8.1 Run OWL2Vec* over the pizza.owl ontology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e78865",
   "metadata": {},
   "source": [
    "I believe this was done above?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee20622",
   "metadata": {},
   "source": [
    "Task 8.2 Compute the similarity between the following elements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be307605",
   "metadata": {},
   "source": [
    "http://www.co-ode.org/ontologies/pizza/pizza.owl#Margherita\n",
    "and margherita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e936f9bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.77699864\n"
     ]
    }
   ],
   "source": [
    "vector = wv['margherita'] # this is just a dictionary,doesnt affect this code right below\n",
    "similarity = wv.similarity('margherita', 'http://www.co-ode.org/ontologies/pizza/pizza.owl#Margherita')\n",
    "print(similarity) # same result as above, but I think thats because we're asking for similarity of same things?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b163a398",
   "metadata": {},
   "source": [
    "http://www.co-ode.org/ontologies/pizza/pizza.owl#Hot and\n",
    "http://www.co-ode.org/ontologies/pizza/pizza.owl#Medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba3a6856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8703375\n"
     ]
    }
   ],
   "source": [
    "similarity = wv.similarity('http://www.co-ode.org/ontologies/pizza/pizza.owl#Hot', 'http://www.co-ode.org/ontologies/pizza/pizza.owl#Medium')\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29330ead",
   "metadata": {},
   "source": [
    "CheesyPizza and CheeseTopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5589b097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98683006\n"
     ]
    }
   ],
   "source": [
    "similarity = wv.similarity('CheesyPizza', 'CheeseTopping')\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a12a6ed",
   "metadata": {},
   "source": [
    "Task 8.3 Get the most similar entities/words for the following elements:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e377f25f",
   "metadata": {},
   "source": [
    "Hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbc2d7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Jalapeno Pepper', 0.9802711606025696), ('Pine Kernel', 0.980215847492218), ('PepperTopping', 0.9797486662864685), ('Medium', 0.9793134331703186), ('HotGreenPepperTopping', 0.9791651964187622), ('GreenPepperTopping', 0.9789767861366272), ('Parma Ham', 0.9779078364372253), ('CajunSpiceTopping', 0.9776169657707214), ('MeatTopping', 0.97737717628479), ('Value Partition', 0.9772661924362183)]\n"
     ]
    }
   ],
   "source": [
    "result = wv.most_similar(positive=['Hot'])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00880f2",
   "metadata": {},
   "source": [
    "http://www.co-ode.org/ontologies/pizza/pizza.owl#CheesyPizza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5764f8b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Key 'http://www.co-ode.org/ontologies/pizza/pizza.owl#CheesyPizza' not present\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mwv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmost_similar\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp://www.co-ode.org/ontologies/pizza/pizza.owl#CheesyPizza\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gensim/models/keyedvectors.py:773\u001b[0m, in \u001b[0;36mKeyedVectors.most_similar\u001b[0;34m(self, positive, negative, topn, clip_start, clip_end, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m    771\u001b[0m     mean\u001b[38;5;241m.\u001b[39mappend(weight \u001b[38;5;241m*\u001b[39m key)\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 773\u001b[0m     mean\u001b[38;5;241m.\u001b[39mappend(weight \u001b[38;5;241m*\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)\n\u001b[1;32m    774\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_index_for(key):\n\u001b[1;32m    775\u001b[0m         all_keys\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_index(key))\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gensim/models/keyedvectors.py:438\u001b[0m, in \u001b[0;36mKeyedVectors.get_vector\u001b[0;34m(self, key, norm)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_vector\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    415\u001b[0m     \u001b[38;5;124;03m\"\"\"Get the key's vector, as a 1D numpy array.\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \n\u001b[1;32m    417\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    436\u001b[0m \n\u001b[1;32m    437\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 438\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m norm:\n\u001b[1;32m    440\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfill_norms()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gensim/models/keyedvectors.py:412\u001b[0m, in \u001b[0;36mKeyedVectors.get_index\u001b[0;34m(self, key, default)\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m default\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 412\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKey \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not present\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Key 'http://www.co-ode.org/ontologies/pizza/pizza.owl#CheesyPizza' not present\""
     ]
    }
   ],
   "source": [
    "result = wv.most_similar('http://www.co-ode.org/ontologies/pizza/pizza.owl#CheesyPizza')\n",
    "print(result) # not sure why this won't run? something to do with it being a url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee6bbd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
